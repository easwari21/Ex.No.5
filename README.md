

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim: To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

### AI Tools Required: 
- ChatGPT
- Gemini
- Any LLM Based Tool
### Step 1: Define the Two Prompt Types
- **Naïve Prompt:** Simple, open-ended, or vague input without much direction.
- **Basic/Refined Prompt:** Clear, detailed, and well-structured prompt that provides specific context or instructions to guide the AI.

The objective is to observe how structure and context affect AI-generated outputs.

---

### Step 2: Prepare Multiple Test Scenarios
Choose various real-world use cases such as:
- Creative writing  
- Factual explanation  
- Professional advice  
- Concept summarization  

For each scenario, create **two prompts** (one naïve and one refined) targeting the same goal but with different levels of detail.

---

### Step 3: Run Experiments
1. Input the naïve prompt for each scenario and record the generated response.
2. Input the corresponding refined prompt and record that response.
3. Evaluate both outputs in terms of **Quality**, **Accuracy**, and **Depth**.

---

## OUTPUT:

The experiment compared AI responses across **four different scenarios** to determine how prompt clarity affects performance.

---

### **Scenario 1: Creative Story Generation**

**Naïve Prompt:**  
> "Write a story about an alien planet."

**Response:**  
Produced a generic plot with predictable alien and spaceship elements.

**Analysis:**  
- **Quality:** Low (Common tropes, repetitive vocabulary)  
- **Depth:** Low (Lacked world-building and character development)

**Basic Prompt:**  
> "Act as a science-fiction author. Write a 4-paragraph story set on the ocean planet *Thalora*, where an explorer discovers intelligent aquatic life. Maintain a tone of wonder and scientific realism."

**Response:**  
Delivered a focused narrative with emotional and descriptive depth, exploring the discovery scientifically and narratively.

**Analysis:**  
- **Quality:** High (Creative and immersive)  
- **Depth:** High (Strong characterization and theme)

**Insight:**  
Structured context leads to creative diversity and deeper storytelling.

---

### **Scenario 2: Answering a Factual Question**

**Naïve Prompt:**  
> "What is climate change?"

**Response:**  
Provided a generic explanation of temperature rise and pollution causes.

**Analysis:**  
- **Accuracy:** Medium  
- **Depth:** Low (Lacked technical clarity)

**Basic Prompt:**  
> "Explain climate change as if you are a university professor teaching environmental science. Focus on greenhouse gas effects and human-induced atmospheric changes. Limit to 200 words."

**Response:**  
A detailed, academic explanation describing mechanisms, data, and long-term impacts.

**Analysis:**  
- **Accuracy:** High  
- **Depth:** High  
- **Tone:** Appropriate for educational context

**Insight:**  
Persona-based prompts ensure domain-specific accuracy and professional tone.

---

### **Scenario 3: Providing Advice or Recommendations**

**Naïve Prompt:**  
> "How can I stay healthy?"

**Response:**  
Generic suggestions like “eat vegetables” and “exercise regularly.”

**Analysis:**  
- **Quality:** Low  
- **Usefulness:** Limited  

**Basic Prompt:**  
> "Act as a certified nutritionist. Give three personalized tips for maintaining good health for a 25-year-old software engineer who works long hours and has a sedentary lifestyle. Present as a numbered list."

**Response:**  
Detailed, practical suggestions like ergonomic posture correction, balanced meals for desk workers, and micro-exercise routines.

**Analysis:**  
- **Quality:** High  
- **Relevance:** High  
- **Depth:** Medium–High  

**Insight:**  
Including user context converts vague advice into actionable guidance.

---

### **Scenario 4: Summarizing a Concept**

**Naïve Prompt:**  
> "Explain Artificial Intelligence."

**Response:**  
A broad overview with no depth or structure.

**Analysis:**  
- **Accuracy:** Medium  
- **Depth:** Low  

**Basic Prompt:**  
> "Summarize the concept of Artificial Intelligence for business executives unfamiliar with technology. Use under 150 words, focus on its impact on productivity, automation, and decision-making."

**Response:**  
Concise, business-oriented explanation linking AI principles to workplace efficiency.

**Analysis:**  
- **Accuracy:** High  
- **Depth:** High  
- **Tone:** Professional and audience-appropriate  

**Insight:**  
Targeting audience and word constraints improves clarity and relevance.

---

## OVERALL ANALYSIS OF PROMPT CLARITY

### **1. Impact on Quality**
**Result:** Refined prompts consistently generated high-quality, contextually rich responses.  
**Reason:** Structured context guided the model toward precise vocabulary, tone, and relevance.

---

### **2. Impact on Accuracy**
**Result:** Basic prompts improved factual and situational accuracy.  
**Reason:** Clear instructions limit the model’s tendency to generalize or drift off-topic.

---

### **3. Impact on Depth**
**Result:** Refined prompts achieved targeted analytical depth.  
**Reason:** Added constraints (role, tone, structure) forced the model to focus on core ideas.

---

### **4. Consistency**
**Observation:** Basic prompts delivered consistently superior results across all tasks.  
**Naïve prompts** only worked equally well for simple, low-stakes queries like quick definitions.

---

## HOW TO STRUCTURE PROMPTS FOR OPTIMAL RESULTS

Use the **C.A.F.T.R. Framework** for designing refined prompts:

| Component | Description | Example |
|------------|--------------|----------|
| **C** | **Context** – Include relevant details | “For a college student studying AI...” |
| **A** | **Audience** – Specify who the response is for | “For a business audience...” |
| **F** | **Format** – Define the desired structure | “Use bullet points or a table” |
| **T** | **Tone** – Set tone and style | “Formal, encouraging, or narrative” |
| **R** | **Role** – Assign a persona | “Act as a professor/doctor/consultant” |

---

## RESULT:

The experiment confirms that **prompt engineering** plays a major role in optimizing AI responses.

### **Key Findings:**
- **Structure is Essential:** Clear frameworks improve output quality.  
- **Constraints Help Focus:** Limiting format, tone, or scope produces more relevant answers.  
- **Persona Power:** Role-based prompts guide the AI to adopt professional tone and expertise.  

# OUTPUT

# RESULT: The prompt for the above said problem executed successfully
