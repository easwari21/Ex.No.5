

# EXP 5: COMPARATIVE ANALYSIS OF DIFFERENT TYPES OF PROMPTING PATTERNS AND EXPLAIN WITH VARIOUS TEST SCENARIOS

# Aim: To test and compare how different pattern models respond to various prompts (broad or unstructured) versus basic prompts (clearer and more refined) across multiple scenarios.  Analyze the quality, accuracy, and depth of the generated responses 

### AI Tools Required: 
- ChatGPT
- Gemini
- Any LLM Based Tool
### Explanation:  

#### Step 1: Define the Two Prompt Types  
- **Naive Prompt:** Simple and unstructured. It gives the AI very little detail or instruction.  
- **Basic Prompt:** More clear and detailed. It gives proper instructions, role, and structure to guide the AI.  

The aim is to find how well the model performs when given better and clearer prompts.  



#### Step 2: Prepare Multiple Test Scenarios  
We choose different types of tasks like:  
- Writing a short story  
- Explaining a factual question  
- Giving advice or recommendations  
- Summarizing a topic  

For each scenario, two prompts are created,one naive and one basic.  



#### Step 3: Run the Experiments  
1. Enter the naïve prompt in ChatGPT and record the output.  
2. Enter the basic prompt and record that output.  
3. Compare both outputs based on quality, accuracy, and depth.  

The test was done with four scenarios. Each one compared the difference between simple and structured prompts.

### Scenario 1: Creative Story  

**Naive Prompt:**  
“Write a story about an alien planet.”  

**Response:**  
A very simple story with common ideas like aliens and spaceships.  

**Analysis:**  
- Quality: Low  
- Depth: Low  

**Basic Prompt:**  
“Write a short story about a scientist who discovers intelligent sea creatures on the planet Thalora. Use a tone of mystery and scientific curiosity.”  

**Response:**  
A better story with clear setting, characters, and emotions.  

**Analysis:**  
- Quality: High  
- Depth: High

### Scenario 2: Factual Question  

**Naïve Prompt:**  
“What is climate change?”  

**Response:**  
A basic answer describing global warming and pollution.  

**Analysis:**  
- Accuracy: Medium  
- Depth: Low  

**Basic Prompt:**  
“Explain climate change in 200 words for a school science report. Focus on greenhouse gases and human causes.”  

**Response:**  
A detailed and clear answer with correct information.  

**Analysis:**  
- Accuracy: High  
- Depth: High 

### Scenario 3: Advice or Recommendation  

**Naïve Prompt:**  
“How can I stay healthy?”  

**Response:**  
Very general suggestions like eating well and doing exercise.  

**Analysis:**  
- Quality: Low  
- Usefulness: Low  

**Basic Prompt:**  
“Act as a nutrition expert. Suggest 3 health tips for a college student who spends long hours studying and using a laptop.”  

**Response:**  
Gave helpful and practical tips about posture, food, and short exercises.  

**Analysis:**  
- Quality: High  
- Usefulness: High  

### Scenario 4: Summarizing a Concept  

**Naïve Prompt:**  
“Explain Artificial Intelligence.”  

**Response:**  
A simple and broad answer with little detail.  

**Analysis:**  
- Accuracy: Medium  
- Depth: Low  

**Basic Prompt:**  
“Summarize Artificial Intelligence in 150 words for business people. Focus on how it helps in automation and decision-making.”  

**Response:**  
A short and focused explanation written in an easy and clear way.  

**Analysis:**  
- Accuracy: High  
- Depth: High  

## Overall Analysis of Prompt Clarity  

**1. Impact on Quality:**  
Basic prompts always gave better-quality responses because they were clear and focused.  

**2. Impact on Accuracy:**  
Refined prompts produced more correct and useful answers that matched the question better.  

**3. Impact on Depth:**  
Clear prompts helped the AI explain in more detail and stay on topic.  

**4. Consistency:**  
Basic prompts worked better in all situations. Naïve prompts were only good for very simple questions.  

## How to Write a Good Prompt  

To get the best results, a good prompt should include:  
- **Role or Persona:** Who the AI should act as.  
- **Task:** What exactly to do.  
- **Context:** Background or data needed.  
- **Format:** How the output should look.  
- **Tone:** The style of writing (formal, friendly, etc.).  

## OUTPUT

The experiment was carried out using four different scenarios to study how prompt clarity affects the quality, accuracy, and depth of AI responses.

| Scenario No | Task Type | Naïve Prompt Result | Basic Prompt Result | Observation |
|--------------|------------|---------------------|----------------------|--------------|
| 1 | Creative Story | Simple, repetitive ideas with no focus | Clear storyline with emotions and unique setting | Basic prompt gave a better and detailed story |
| 2 | Factual Question | Gave a general definition | Focused answer with correct details | Refined prompt improved accuracy and structure |
| 3 | Giving Advice | Common and general tips | Personalized, practical advice with reasoning | Refined prompt produced more helpful output |
| 4 | Summarization | Too broad and unclear | Well-structured and audience-specific summary | Clear prompts improved depth and relevance |

### Observation:
- Basic prompts gave more structured and meaningful outputs.
- Naïve prompts were generic and less detailed.
- The clarity of the prompt directly improved the model’s response in all cases.


# RESULT: 
The prompt for the above said problem executed successfully
